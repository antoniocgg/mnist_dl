{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plain TensorFlow (no Keras) on MNIST\n",
    "Used the default Kaggle enviromnent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'train.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data in a Pandas dataset and separetes the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "labeled_images = pd.read_csv('../input/train.csv')\n",
    "test_images = pd.read_csv('../input/test.csv')\n",
    "\n",
    "images=np.array(labeled_images.iloc[0:41500 , 1:])\n",
    "labels = np.array(labeled_images.iloc[0:41500, :1]).ravel()\n",
    "\n",
    "X_valid = np.array(labeled_images.iloc[41500: , 1:])\n",
    "y_valid = np.array(labeled_images.iloc[41500:, :1]).ravel()\n",
    "\n",
    "test_images= np.array(test_images.iloc[0:])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "Use this technique to increase the dataset. \n",
    "We could zoom in, out and tilt some degrees. But just shifted the images left, right, up and down by one pixel, creating four plus images from each dataset image. Now our dataset is 5X bigger.\n",
    "\n",
    "This techique prevents overfitting and makes our model to generalize better. It's a welcome costless dataset increase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207500, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "def shift_image(image, dx, dy):\n",
    "    image = image.reshape((28, 28))\n",
    "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
    "    return shifted_image.reshape([-1])\n",
    "\n",
    "X_train_augmented = [image for image in images]\n",
    "y_train_augmented = [label for label in labels]\n",
    "\n",
    "for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):   #variação de 1 pixels em todas as direções\n",
    "    for image, label in zip(images, labels):\n",
    "        X_train_augmented.append(shift_image(image, dx, dy))\n",
    "        y_train_augmented.append(label)\n",
    "\n",
    "X_train = np.array(X_train_augmented)\n",
    "y_train = np.array(y_train_augmented)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "The google library for machine learning. \n",
    "\n",
    "At first, we define our input wich is 28X28 (image size in pixels)\n",
    "Then we choose how many hidden layers we gonna use. In this case, the first hidden layer will have 300 nodes, and the second layer 100. This is an arbitrary decision, but definetly impacts the model performance. 2 hidden layers seems enough, but the number of nodes may. 300 and 100 seems to muuch, but the computation cost is not too big. \n",
    "\n",
    "The last layer (n_output) is the number of classes (0...9 digits)\n",
    "\n",
    "lerning rate: too small and the network will never reach the optimum. Too big and the NN will diverge. \n",
    "batch normalization momentum : chose values close to 1\n",
    "\n",
    "Dropout rate is the number of nodes that will be dropped during training phase. Dropout increases the NN performance and avoids overfitting.\n",
    "This NN uses neurons with ELU activation function, because it works better than sigmoid and RELU. \n",
    "\n",
    "Also, some authors says that Nesterov is a better optimizer than ADAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-23a49a7b4343>:20: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-5-23a49a7b4343>:34: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-23a49a7b4343>:36: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate=0.01\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "\n",
    "dropout_rate =0.5   #dropout\n",
    "X_drop= tf.layers.dropout(X,dropout_rate,training=training) #dropout\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)  #dropout\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training) #dropout\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9, use_nesterov=True)  #usei Nesterov\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.984\n",
      "1 Validation accuracy: 0.984\n",
      "2 Validation accuracy: 0.984\n",
      "3 Validation accuracy: 0.974\n",
      "4 Validation accuracy: 0.984\n",
      "5 Validation accuracy: 0.984\n",
      "6 Validation accuracy: 0.988\n",
      "7 Validation accuracy: 0.986\n",
      "8 Validation accuracy: 0.986\n",
      "9 Validation accuracy: 0.988\n",
      "10 Validation accuracy: 0.988\n",
      "11 Validation accuracy: 0.988\n",
      "12 Validation accuracy: 0.986\n",
      "13 Validation accuracy: 0.984\n",
      "14 Validation accuracy: 0.984\n",
      "15 Validation accuracy: 0.988\n",
      "16 Validation accuracy: 0.992\n",
      "17 Validation accuracy: 0.988\n",
      "18 Validation accuracy: 0.986\n",
      "19 Validation accuracy: 0.988\n",
      "20 Validation accuracy: 0.988\n",
      "21 Validation accuracy: 0.992\n",
      "22 Validation accuracy: 0.986\n",
      "23 Validation accuracy: 0.988\n",
      "24 Validation accuracy: 0.99\n",
      "25 Validation accuracy: 0.99\n",
      "26 Validation accuracy: 0.992\n",
      "27 Validation accuracy: 0.988\n",
      "28 Validation accuracy: 0.986\n",
      "29 Validation accuracy: 0.988\n",
      "30 Validation accuracy: 0.99\n",
      "31 Validation accuracy: 0.99\n",
      "32 Validation accuracy: 0.992\n",
      "33 Validation accuracy: 0.99\n",
      "34 Validation accuracy: 0.994\n",
      "35 Validation accuracy: 0.99\n",
      "36 Validation accuracy: 0.992\n",
      "37 Validation accuracy: 0.992\n",
      "38 Validation accuracy: 0.988\n",
      "39 Validation accuracy: 0.992\n",
      "40 Validation accuracy: 0.992\n",
      "41 Validation accuracy: 0.994\n",
      "42 Validation accuracy: 0.99\n",
      "43 Validation accuracy: 0.99\n",
      "44 Validation accuracy: 0.99\n",
      "45 Validation accuracy: 0.992\n",
      "46 Validation accuracy: 0.99\n",
      "47 Validation accuracy: 0.988\n",
      "48 Validation accuracy: 0.988\n",
      "49 Validation accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    X_scaled=test_images\n",
    "    Z=logits.eval(feed_dict={X:X_scaled})\n",
    "    results=np.argmax(Z,axis=1)\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle results\n",
    "If you are in the Kaggle contest, use the code below to submit your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(results)\n",
    "submission.index.name='ImageId'\n",
    "submission.index+=1\n",
    "submission.columns=['Label']\n",
    "submission.to_csv('Submission.csv', header=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
